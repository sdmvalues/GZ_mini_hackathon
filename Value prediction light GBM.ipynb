{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/learning_curve.py:22: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the functions are moved. This module will be removed in 0.20\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "notebookstart= time.time()\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import gc\n",
    "import random\n",
    "random.seed(2018)\n",
    "from sklearn import *\n",
    "# Models Packages\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import feature_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Gradient Boosting\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Load Stage\n"
     ]
    }
   ],
   "source": [
    "id_col = \"ID\"\n",
    "target_var = \"target\"\n",
    "\n",
    "# House Keeping Parameters\n",
    "Debug = False\n",
    "Home = False\n",
    "Build_Results_csv = False # if running for first time\n",
    "\n",
    "results = pd.DataFrame(columns = [\"Rounds\",\"Score\",\"STDV\", \"LB\", \"Parameters\"])\n",
    "print(\"Data Load Stage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = pd.read_csv('train.csv', index_col = id_col)\n",
    "if Debug is True : training = training.sample(100)\n",
    "traindex = training.index\n",
    "testing = pd.read_csv('test.csv', index_col = id_col)\n",
    "if Debug is True : testing = testing.sample(100)\n",
    "testdex = testing.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: 4459 Rows, 4991 Columns\n",
      "Test shape: 49342 Rows, 4991 Columns\n"
     ]
    }
   ],
   "source": [
    "y = np.log1p(training[target_var])\n",
    "training.drop(target_var,axis=1, inplace=True)\n",
    "print('Train shape: {} Rows, {} Columns'.format(*training.shape))\n",
    "print('Test shape: {} Rows, {} Columns'.format(*testing.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combine Train and Test\n",
      "\n",
      "All Data shape: 53801 Rows, 4991 Columns\n"
     ]
    }
   ],
   "source": [
    "print(\"Combine Train and Test\")\n",
    "df = pd.concat([training,testing],axis=0)\n",
    "del training, testing\n",
    "gc.collect()\n",
    "print('\\nAll Data shape: {} Rows, {} Columns'.format(*df.shape))\n",
    "\n",
    "# Modeling Datasets\n",
    "test_df = df.loc[testdex,:]\n",
    "vocab = df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting LightGBM. Train shape: (49342, 4991), Test shape: (49342, 4991)\n",
      "Feature Num:  4991\n",
      "Light Gradient Boosting Regressor: \n",
      "[50]\tcv_agg's rmse: 1.58742 + 0.0305161\n",
      "[100]\tcv_agg's rmse: 1.50458 + 0.0316924\n",
      "[150]\tcv_agg's rmse: 1.46337 + 0.0325538\n",
      "[200]\tcv_agg's rmse: 1.44265 + 0.0327991\n",
      "[250]\tcv_agg's rmse: 1.43354 + 0.032863\n",
      "[300]\tcv_agg's rmse: 1.43088 + 0.0337591\n",
      "[350]\tcv_agg's rmse: 1.42942 + 0.0337614\n",
      "[400]\tcv_agg's rmse: 1.43018 + 0.0342158\n"
     ]
    }
   ],
   "source": [
    "lgtrain = lgb.Dataset(df.loc[traindex,vocab],y ,feature_name = \"auto\")\n",
    "print(\"Starting LightGBM. Train shape: {}, Test shape: {}\".format(df.loc[testdex,:].shape,test_df.shape))\n",
    "print(\"Feature Num: \",len(vocab))\n",
    "del df; gc.collect();\n",
    "\n",
    "print(\"Light Gradient Boosting Regressor: \")\n",
    "lgbm_params =  {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': 'rmse',\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"num_leaves\": 200,\n",
    "    \"feature_fraction\": 0.50,\n",
    "    \"bagging_fraction\": 0.50,\n",
    "    'bagging_freq': 4,\n",
    "    \"max_depth\": -1,\n",
    "    \"reg_alpha\": 0.3,\n",
    "    \"reg_lambda\": 0.1,\n",
    "    #\"min_split_gain\":0.2,\n",
    "    \"min_child_weight\":10,\n",
    "    'zero_as_missing':True\n",
    "}\n",
    "\n",
    "modelstart= time.time()\n",
    "# Find Optimal Parameters / Boosting Rounds\n",
    "lgb_cv = lgb.cv(\n",
    "    params = lgbm_params,\n",
    "    train_set = lgtrain,\n",
    "    num_boost_round=2500,\n",
    "    stratified=False,\n",
    "    nfold = 5,\n",
    "    verbose_eval=50,\n",
    "    seed = 23,\n",
    "    early_stopping_rounds=75)\n",
    "\n",
    "optimal_rounds = np.argmin(lgb_cv['rmse-mean'])\n",
    "best_cv_score = min(lgb_cv['rmse-mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimal Round: 339\n",
      "Optimal Score: 1.4292676122745214 + 0.03369025245241405\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nOptimal Round: {}\\nOptimal Score: {} + {}\".format(\n",
    "    optimal_rounds,best_cv_score,lgb_cv['rmse-stdv'][optimal_rounds]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Rate:  0.012\n",
      "[200]\tcv_agg's rmse: 1.4344 + 0.0334958\n",
      "Optimal Round: 284\n",
      "Optimal Score: 1.4287010145278027 + 0.034950291968031635\n",
      "Learning Rate:  0.008\n",
      "[200]\tcv_agg's rmse: 1.45785 + 0.0314299\n",
      "[400]\tcv_agg's rmse: 1.42848 + 0.0341142\n",
      "Optimal Round: 445\n",
      "Optimal Score: 1.4269354837748918 + 0.0343219787670181\n",
      "Learning Rate:  0.016\n",
      "[200]\tcv_agg's rmse: 1.42889 + 0.0343656\n",
      "Optimal Round: 195\n",
      "Optimal Score: 1.428719227824455 + 0.034146578426916964\n"
     ]
    }
   ],
   "source": [
    "results = results.append({\"Rounds\": optimal_rounds,\n",
    "                          \"Score\": best_cv_score,\n",
    "                          \"STDV\": lgb_cv['rmse-stdv'][optimal_rounds],\n",
    "                          \"LB\": None,\n",
    "                          \"Parameters\": lgbm_params}, ignore_index=True)\n",
    "        \n",
    "learning_rates = [0.012,0.008,0.016]\n",
    "for param in learning_rates:\n",
    "    print(\"Learning Rate: \", param)\n",
    "    modelstart= time.time()\n",
    "    lgbm_params[\"learning_rate\"] = param\n",
    "    # Find Optimal Parameters / Boosting Rounds\n",
    "    lgb_cv = lgb.cv(\n",
    "        params = lgbm_params,\n",
    "        train_set = lgtrain,\n",
    "        num_boost_round=10000,\n",
    "        stratified=False,\n",
    "        nfold = 5,\n",
    "        verbose_eval=200,\n",
    "        seed = 23,\n",
    "        early_stopping_rounds=75)\n",
    "\n",
    "    optimal_rounds = np.argmin(lgb_cv['rmse-mean'])\n",
    "    best_cv_score = min(lgb_cv['rmse-mean'])\n",
    "\n",
    "    print(\"Optimal Round: {}\\nOptimal Score: {} + {}\".format(\n",
    "        optimal_rounds,best_cv_score,lgb_cv['rmse-stdv'][optimal_rounds]))\n",
    "\n",
    "    results = results.append({\"Rounds\": optimal_rounds,\n",
    "                              \"Score\": best_cv_score,\n",
    "                              \"STDV\": lgb_cv['rmse-stdv'][optimal_rounds],\n",
    "                              \"LB\": None,\n",
    "                              \"Parameters\": lgbm_params}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Home is True:\n",
    "        with open('results.csv', 'a') as f:\n",
    "            results.to_csv(f, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model_params = results.iloc[results[\"Score\"].idxmin(),:][\"Parameters\"]\n",
    "optimal_rounds = results.iloc[results[\"Score\"].idxmin(),:][\"Rounds\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "allmodelstart= time.time()\n",
    "# Run Model with different Seeds\n",
    "multi_seed_pred = dict()\n",
    "all_feature_importance_df  = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:  27\n",
      "Seed:  22\n",
      "Seed:  300\n",
      "Seed:  401\n",
      "Seed:  7\n"
     ]
    }
   ],
   "source": [
    "all_seeds = [27,22,300,401,7]\n",
    "for seeds_x in all_seeds:\n",
    "    modelstart= time.time()\n",
    "    print(\"Seed: \", seeds_x,)\n",
    "    # Go Go Go\n",
    "    final_model_params[\"seed\"] = seeds_x\n",
    "    lgb_reg = lgb.train(\n",
    "        final_model_params,\n",
    "        lgtrain,\n",
    "        num_boost_round = optimal_rounds + 1,\n",
    "        verbose_eval=200)\n",
    "\n",
    "    # Feature Importance\n",
    "    fold_importance_df = pd.DataFrame()\n",
    "    fold_importance_df[\"feature\"] = vocab\n",
    "    fold_importance_df[\"importance\"] = lgb_reg.feature_importance()\n",
    "    all_feature_importance_df = pd.concat([all_feature_importance_df, fold_importance_df], axis=0)\n",
    "\n",
    "    multi_seed_pred[seeds_x] =  list(lgb_reg.predict(test_df))\n",
    "    #del lgb_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48df886f9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0deb4b6a8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34b15f335</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a8cb14b00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2f0771a37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     feature  importance\n",
       "0  48df886f9           0\n",
       "1  0deb4b6a8           0\n",
       "2  34b15f335           0\n",
       "3  a8cb14b00           0\n",
       "4  2f0771a37           0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_feature_importance_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Model Runtime: 3.65 Minutes\n",
      "Runtime: 14.49 Minutes\n"
     ]
    }
   ],
   "source": [
    "print(\"All Model Runtime: %0.2f Minutes\"%((time.time() - allmodelstart)/60))\n",
    "\n",
    "sub_preds = pd.DataFrame.from_dict(multi_seed_pred).replace(0,0.000001)\n",
    "del multi_seed_pred; gc.collect();\n",
    "\n",
    "lgb_ans = np.expm1(sub_preds.mean(axis=1))\n",
    "mean_sub = np.expm1(sub_preds.mean(axis=1).rename(target_var))\n",
    "mean_sub.index = testdex\n",
    "\n",
    "# Submit\n",
    "mean_sub.to_csv('lgb.csv'\n",
    "            ,index = True, header=True)\n",
    "print(\"Runtime: %0.2f Minutes\"%((time.time() - notebookstart)/60))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "binary mode doesn't take an encoding argument",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-61be8412dd49>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'finalized_lgb_model.sav'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mlgb_reg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utf8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: binary mode doesn't take an encoding argument"
     ]
    }
   ],
   "source": [
    "filename = 'finalized_lgb_model.sav'\n",
    "pickle.dump( lgb_reg, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
